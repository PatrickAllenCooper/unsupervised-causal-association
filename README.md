# unsupervised-causal-association
Can unsupervised networks capture causal associations in a manner that is general and robust?

# Premise

It is no surprise that GPT-3 and large transformer models demonstrate some capability 

Unsupervised networks have demonstrated stellar capabilities when it comes to capturing spatial or temporal data in visual scenes. It has even been demonstrated that such networks are capable of expressing uncertainty in visual reconstructions.

There remains the question which I believe has yet to be solved as to whether they can be said to generally express counterfacutal awareness.

Further, we should seek to pose the question as to what expression causal belief will take when we traverse latent space representation.

## Two Fundamental Circumstances
There are two sorts of scenarios where such models are useful. The first corresponds to those environments where we have undefined variables in the environment which cause our knowledge statements to be partial. In such cases, modeling metro timing, etc. we accept that unknowns are responsible for the irregularities of our outcomes. In some simulation contexts however probabilistic statements are just representations of an expression of incomplete information. In such cases, we make use of the uniformity of sampling of some variables to create a subsampling of discrete variables. These can be used to construct distributions which can then be compared to generate insights about the intermediate states of the beliefs of such networks.

# Methodology

We must allow the model to cognize 2 eventual states which are contingent on a singular choice which must be embedded within time. To ensure this happens I propse using a variational autoencoder and based on the beta-VAE architecture, we will then use this arhitecture to devise a novel way to embedd this into the state representation using mutual information as a comparison metric. Solving this will take extensive experimentation.

Perhaps the simplest way to demonstrate this behavior is by using natural language. We will prepare a small set of contrived causal associations and ask the system to generalize.
While these scenarios are not particularly interestign from a purely experimental perspective, their relevenace for encoding various kinds of knowledge justifies some specific examination.

We can note that these associations are fundamentally discrete. This implies that we must make use of tools to parse the problem in a superior way. That is, by 

### Scenario One: Sine Qua Non
The establishment of a solitary sufficient condition such that without it what follows will not occur.

### Scenario Two: Sufficiency vs Necessity
The distinction in latent space variable interactions such that it is clear the network can congize the difference between those attributes which are sufficient and those which are necessary.

### Scenario Three: Overdetermination
The notion that we may have many events which are sufficient for the singularly described outcome occuring simultaneously.

### Scenario Four: Bayesian Inference
Demonstrate general capabilities to infer bayesian probabilities.

# Experiments
### Trial One Natural Language
Demonstrate all scenarios for natural language scenarios.

### Visual Experimentation
Demonstrate all scenarios for visual images.

### Transfer Network
Demonstrate the generalization of causality to a host of different network types using a set of adapters.
